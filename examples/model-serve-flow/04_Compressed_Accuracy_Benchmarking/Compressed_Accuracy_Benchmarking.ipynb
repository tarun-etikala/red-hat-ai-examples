{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46dec15d-d789-4e22-b9ea-5eec04bf9230",
   "metadata": {},
   "source": [
    "## Evaluate the accuracy of the compressed model\n",
    "\n",
    "This notebook evaluates the **compressed model** on the same standard benchmarks that you used to evaluate the base model.\n",
    "\n",
    "**Goal**: Measure the accuracy of the compressed model so that you can compare its accuracy with that of the base model and assess the impact of compression.\n",
    "\n",
    "**Key actions**:\n",
    "\n",
    "- Create a function named **evaluate** that uses the `simple_evaluate` function from the LMEval tool to test the base model.\n",
    "\n",
    "- Benchmark on multiple datasets:\n",
    "\n",
    "    - MMLU: General knowledge across subjects.\n",
    "\n",
    "    - IFeval: Instruction-following tasks.\n",
    "\n",
    "    - ARC: Logical and scientific reasoning.\n",
    "    \n",
    "    - HellaSwag: Commonsense completion.\n",
    "\n",
    "- Collect metrics such as accuracy, accuracy_norm, and task-specific scores.\n",
    "\n",
    "- Save results in JSON format.\n",
    "\n",
    "**Outcome**:\n",
    "\n",
    "- Quantitative metrics for the compressed model.\n",
    "\n",
    "- Confidence that the model is good enough in terms of accuracy.\n",
    "\n",
    "For details on evaluating LLMs, see [Evaluate the Accuracy of the Base and Compressed Models](../docs/Accuracy_Evaluation.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c18af3e",
   "metadata": {},
   "source": [
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d2bcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment the following lines to install dependencies if dependencies were not installed in 01_Base_Accuracy_Benchmarking/Base.ipynb\n",
    "# !pip install -qqU ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1f45e6-3f29-4922-b85f-2b77be643530",
   "metadata": {
    "tags": [
     "parameters",
     "keep_output"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from lm_eval.utils import make_table\n",
    "from utils import evaluate, load_pickle, save_pickle\n",
    "\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116e3f9b-f437-4f3f-9391-c23b31fc5ef5",
   "metadata": {},
   "source": [
    "### Check GPU memory\n",
    "\n",
    "To make sure that you have enough GPU memory to run this notebook:\n",
    "\n",
    "1. In a terminal window, run the `nvidia-smi` command.\n",
    "\n",
    "2. If there are processes that are GPU memory that this notebook requires, run the `kill -9 <pid>` command for each process to stop it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66d763a-945a-40bd-9e51-896fbe2206e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bfb397-d989-4a4b-8636-511a25c12ed6",
   "metadata": {},
   "source": [
    "### Define evaluation benchmarking datasets\n",
    "\n",
    "Evaluate the compressed model on the same benchmarks as the base model to make the results comparable.\n",
    "\n",
    "The following benchmark datasets evaluate on multiple tasks:\n",
    "- MMLU: General knowledge across 57 subjects\n",
    "- IFeval: Instruction-following capability\n",
    "- ARC: Logical & scientific reasoning\n",
    "- HellaSwag: Commonsense completion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383befc1-e7b7-4540-af75-a3d5ce28786d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define tasks you want to evaluate the model on\n",
    "tasks = [\"mmlu\", \"arc_easy\", \"hellaswag\", \"ifeval\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72ddc52-4acd-4230-9681-f84201f19e33",
   "metadata": {},
   "source": [
    "### Evaluate the compressed model\n",
    "\n",
    "**NOTE**: \n",
    "- Running the evaluation on the entire list of tasks can take a long time (5 hours or more depending on resources). For the purpose of testing, run the evaluation on a single task instead.\n",
    "\n",
    "- The results are stored as a **results.pkl** file in the directory defined by **compressed_results_dir**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b759ca-440b-4491-abba-486fe2c1afe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting directories\n",
    "compressed_model_path = (\n",
    "    \"../compressed_model/RedHatAI-Llama-3.1-8B-Instruct-int8-dynamic\"\n",
    ")\n",
    "compressed_results_dir = \"../results/compressed_accuracy\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c5da23",
   "metadata": {},
   "source": [
    "**NOTE** If the following warning appears when you run the next cell, you can safely ignore it:\n",
    "\n",
    "`The tokenizer you are loading from '../base_model' with an incorrect regex pattern... This will lead to incorrect tokenization.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c849dd-535e-442c-82e9-d1fbeed500d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the compressed model and save results in pkl format\n",
    "comp_acc = evaluate(\n",
    "    compressed_model_path,\n",
    "    tasks,\n",
    "    limit=None,\n",
    "    batch_size=16,\n",
    "    apply_chat_template=True,\n",
    "    verbosity=None,\n",
    ")\n",
    "save_pickle(compressed_results_dir, comp_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20e51ac-f4c3-4276-b2fe-df595a963443",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "comp_results = load_pickle(compressed_results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75978c77-f222-47ac-8897-6be82328378d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print results for the compressed model\n",
    "print(make_table(comp_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04a4f4c",
   "metadata": {},
   "source": [
    "Example accuracy results for the compressed model:\n",
    "\n",
    "```text\n",
    "|                 Tasks                 |Version|Filter|n-shot|        Metric         |   |Value |   |Stderr|\n",
    "|---------------------------------------|------:|------|-----:|-----------------------|---|-----:|---|------|\n",
    "|arc_easy                               |      1|none  |     0|acc                    |↑  |0.8106|±  |0.0080|\n",
    "|                                       |       |none  |     0|acc_norm               |↑  |0.7555|±  |0.0088|\n",
    "|hellaswag                              |      1|none  |     0|acc                    |↑  |0.5734|±  |0.0049|\n",
    "|                                       |       |none  |     0|acc_norm               |↑  |0.7277|±  |0.0044|\n",
    "|ifeval                                 |      4|none  |     0|inst_level_loose_acc   |↑  |0.8549|±  |   N/A|\n",
    "|                                       |       |none  |     0|inst_level_strict_acc  |↑  |0.8237|±  |   N/A|\n",
    "|                                       |       |none  |     0|prompt_level_loose_acc |↑  |0.7893|±  |0.0175|\n",
    "|                                       |       |none  |     0|prompt_level_strict_acc|↑  |0.7449|±  |0.0188|\n",
    "|mmlu                                   |      2|none  |      |acc                    |↑  |0.6311|±  |0.0038|\n",
    "| - humanities                          |      2|none  |      |acc                    |↑  |0.5911|±  |0.0068|\n",
    "|  - formal_logic                       |      1|none  |     0|acc                    |↑  |0.4921|±  |0.0447|\n",
    "|  - high_school_european_history       |      1|none  |     0|acc                    |↑  |0.7697|±  |0.0329|\n",
    "|  - high_school_us_history             |      1|none  |     0|acc                    |↑  |0.7990|±  |0.0281|\n",
    "|  - high_school_world_history          |      1|none  |     0|acc                    |↑  |0.8186|±  |0.0251|\n",
    "|  - international_law                  |      1|none  |     0|acc                    |↑  |0.7686|±  |0.0385|\n",
    "|  - jurisprudence                      |      1|none  |     0|acc                    |↑  |0.7500|±  |0.0419|\n",
    "|  - logical_fallacies                  |      1|none  |     0|acc                    |↑  |0.7669|±  |0.0332|\n",
    "|  - moral_disputes                     |      1|none  |     0|acc                    |↑  |0.6792|±  |0.0251|\n",
    "|  - moral_scenarios                    |      1|none  |     0|acc                    |↑  |0.4369|±  |0.0166|\n",
    "|  - philosophy                         |      1|none  |     0|acc                    |↑  |0.6913|±  |0.0262|\n",
    "|  - prehistory                         |      1|none  |     0|acc                    |↑  |0.7191|±  |0.0250|\n",
    "|  - professional_law                   |      1|none  |     0|acc                    |↑  |0.4687|±  |0.0127|\n",
    "|  - world_religions                    |      1|none  |     0|acc                    |↑  |0.8363|±  |0.0284|\n",
    "| - other                               |      2|none  |      |acc                    |↑  |0.7132|±  |0.0079|\n",
    "|  - business_ethics                    |      1|none  |     0|acc                    |↑  |0.6500|±  |0.0479|\n",
    "|  - clinical_knowledge                 |      1|none  |     0|acc                    |↑  |0.7019|±  |0.0282|\n",
    "|  - college_medicine                   |      1|none  |     0|acc                    |↑  |0.6474|±  |0.0364|\n",
    "|  - global_facts                       |      1|none  |     0|acc                    |↑  |0.4100|±  |0.0494|\n",
    "|  - human_aging                        |      1|none  |     0|acc                    |↑  |0.6861|±  |0.0311|\n",
    "|  - management                         |      1|none  |     0|acc                    |↑  |0.7864|±  |0.0406|\n",
    "|  - marketing                          |      1|none  |     0|acc                    |↑  |0.8462|±  |0.0236|\n",
    "|  - medical_genetics                   |      1|none  |     0|acc                    |↑  |0.7700|±  |0.0423|\n",
    "|  - miscellaneous                      |      1|none  |     0|acc                    |↑  |0.8059|±  |0.0141|\n",
    "|  - nutrition                          |      1|none  |     0|acc                    |↑  |0.7614|±  |0.0244|\n",
    "|  - professional_accounting            |      1|none  |     0|acc                    |↑  |0.4965|±  |0.0298|\n",
    "|  - professional_medicine              |      1|none  |     0|acc                    |↑  |0.7721|±  |0.0255|\n",
    "|  - virology                           |      1|none  |     0|acc                    |↑  |0.5361|±  |0.0388|\n",
    "| - social sciences                     |      2|none  |      |acc                    |↑  |0.7394|±  |0.0077|\n",
    "|  - econometrics                       |      1|none  |     0|acc                    |↑  |0.4474|±  |0.0468|\n",
    "|  - high_school_geography              |      1|none  |     0|acc                    |↑  |0.7778|±  |0.0296|\n",
    "|  - high_school_government_and_politics|      1|none  |     0|acc                    |↑  |0.8187|±  |0.0278|\n",
    "|  - high_school_macroeconomics         |      1|none  |     0|acc                    |↑  |0.6487|±  |0.0242|\n",
    "|  - high_school_microeconomics         |      1|none  |     0|acc                    |↑  |0.7437|±  |0.0284|\n",
    "|  - high_school_psychology             |      1|none  |     0|acc                    |↑  |0.8606|±  |0.0149|\n",
    "|  - human_sexuality                    |      1|none  |     0|acc                    |↑  |0.7634|±  |0.0373|\n",
    "|  - professional_psychology            |      1|none  |     0|acc                    |↑  |0.6814|±  |0.0189|\n",
    "|  - public_relations                   |      1|none  |     0|acc                    |↑  |0.6636|±  |0.0453|\n",
    "|  - security_studies                   |      1|none  |     0|acc                    |↑  |0.6857|±  |0.0297|\n",
    "|  - sociology                          |      1|none  |     0|acc                    |↑  |0.8408|±  |0.0259|\n",
    "|  - us_foreign_policy                  |      1|none  |     0|acc                    |↑  |0.8600|±  |0.0349|\n",
    "| - stem                                |      2|none  |      |acc                    |↑  |0.5043|±  |0.0084|\n",
    "|  - abstract_algebra                   |      1|none  |     0|acc                    |↑  |0.2500|±  |0.0435|\n",
    "|  - anatomy                            |      1|none  |     0|acc                    |↑  |0.6444|±  |0.0414|\n",
    "|  - astronomy                          |      1|none  |     0|acc                    |↑  |0.6842|±  |0.0378|\n",
    "|  - college_biology                    |      1|none  |     0|acc                    |↑  |0.7431|±  |0.0365|\n",
    "|  - college_chemistry                  |      1|none  |     0|acc                    |↑  |0.4500|±  |0.0500|\n",
    "|  - college_computer_science           |      1|none  |     0|acc                    |↑  |0.4200|±  |0.0496|\n",
    "|  - college_mathematics                |      1|none  |     0|acc                    |↑  |0.2700|±  |0.0446|\n",
    "|  - college_physics                    |      1|none  |     0|acc                    |↑  |0.3824|±  |0.0484|\n",
    "|  - computer_security                  |      1|none  |     0|acc                    |↑  |0.7300|±  |0.0446|\n",
    "|  - conceptual_physics                 |      1|none  |     0|acc                    |↑  |0.6000|±  |0.0320|\n",
    "|  - electrical_engineering             |      1|none  |     0|acc                    |↑  |0.6069|±  |0.0407|\n",
    "|  - elementary_mathematics             |      1|none  |     0|acc                    |↑  |0.4048|±  |0.0253|\n",
    "|  - high_school_biology                |      1|none  |     0|acc                    |↑  |0.7774|±  |0.0237|\n",
    "|  - high_school_chemistry              |      1|none  |     0|acc                    |↑  |0.4729|±  |0.0351|\n",
    "|  - high_school_computer_science       |      1|none  |     0|acc                    |↑  |0.5800|±  |0.0496|\n",
    "|  - high_school_mathematics            |      1|none  |     0|acc                    |↑  |0.2519|±  |0.0265|\n",
    "|  - high_school_physics                |      1|none  |     0|acc                    |↑  |0.3444|±  |0.0388|\n",
    "|  - high_school_statistics             |      1|none  |     0|acc                    |↑  |0.4213|±  |0.0337|\n",
    "|  - machine_learning                   |      1|none  |     0|acc                    |↑  |0.4732|±  |0.0474|\n",
    "\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
