{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Real-Time Progress Tracking with Kubeflow Trainer\n",
        "\n",
        "This notebook demonstrates how to monitor training progress in real-time using Kubeflow Trainer v2 on Red Hat OpenShift AI.\n",
        "\n",
        "**What you will learn:**\n",
        "- How progress tracking works with RHAI trainers\n",
        "- How to view real-time training metrics\n",
        "- How to interpret progress annotations\n",
        "\n",
        "**Prerequisites:**\n",
        "- Access to an OpenShift AI cluster with Kubeflow Trainer enabled\n",
        "- A workbench with Python 3.9+"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Install the Kubeflow SDK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install \"kubeflow @ git+https://github.com/opendatahub-io/kubeflow-sdk.git@v0.2.1+rhai0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify installation\n",
        "import kubeflow\n",
        "print(f\"Kubeflow SDK version: {kubeflow.__version__}\")\n",
        "\n",
        "from kubeflow.trainer import TrainerClient\n",
        "from kubeflow.trainer.rhai import TransformersTrainer\n",
        "from kubeflow.common.types import KubernetesBackendConfig\n",
        "\n",
        "print(\"SDK imported successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Configuration\n",
        "\n",
        "Progress tracking is **enabled by default** when using `TransformersTrainer`. No additional configuration is needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "NAMESPACE = None  # None = use current namespace from kubeconfig\n",
        "NUM_NODES = 2\n",
        "GPUS_PER_NODE = 1\n",
        "\n",
        "print(f\"Configuration:\")\n",
        "print(f\"  Nodes: {NUM_NODES}\")\n",
        "print(f\"  GPUs per node: {GPUS_PER_NODE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Define the training function\n",
        "\n",
        "We use a simple training job with multiple epochs to demonstrate progress tracking over time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_func():\n",
        "    \"\"\"Training function with multiple epochs for progress demonstration.\"\"\"\n",
        "    import os\n",
        "    import torch\n",
        "    from transformers import (\n",
        "        AutoModelForSequenceClassification,\n",
        "        AutoTokenizer,\n",
        "        Trainer,\n",
        "        TrainingArguments,\n",
        "    )\n",
        "    from datasets import load_dataset\n",
        "    \n",
        "    rank = int(os.environ.get(\"RANK\", 0))\n",
        "    local_rank = int(os.environ.get(\"LOCAL_RANK\", 0))\n",
        "    \n",
        "    print(f\"Starting training on rank {rank}\")\n",
        "    \n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.set_device(local_rank)\n",
        "    \n",
        "    # Load a small model for quick demonstration\n",
        "    model_name = \"distilbert-base-uncased\"\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    \n",
        "    # Load a subset of IMDB for demonstration\n",
        "    dataset = load_dataset(\"imdb\", split=\"train[:500]\")\n",
        "    \n",
        "    def tokenize_function(examples):\n",
        "        return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
        "    \n",
        "    tokenized_dataset = dataset.map(tokenize_function, batched=True, remove_columns=[\"text\"])\n",
        "    \n",
        "    # Train for 2 epochs to show progress over time\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=\"/tmp/output\",\n",
        "        num_train_epochs=2,  # Multiple epochs to observe progress\n",
        "        per_device_train_batch_size=8,\n",
        "        learning_rate=2e-5,\n",
        "        logging_steps=5,  # Frequent logging for progress updates\n",
        "        save_strategy=\"no\",\n",
        "        report_to=\"none\",\n",
        "        ddp_find_unused_parameters=False,\n",
        "    )\n",
        "    \n",
        "    trainer = Trainer(model=model, args=training_args, train_dataset=tokenized_dataset)\n",
        "    trainer.train()\n",
        "    print(f\"Training complete on rank {rank}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Submit the training job\n",
        "\n",
        "When using `TransformersTrainer`, progress tracking is automatically enabled. The trainer instruments your code to report metrics without any changes to your training function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create TransformersTrainer - progress tracking is ON by default\n",
        "trainer = TransformersTrainer(\n",
        "    func=train_func,\n",
        "    num_nodes=NUM_NODES,\n",
        "    resources_per_node={\"nvidia.com/gpu\": GPUS_PER_NODE},\n",
        "    # enable_progression_tracking=True  # This is the default, no need to specify\n",
        ")\n",
        "\n",
        "print(\"Trainer configured with progress tracking enabled\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create client and submit job\n",
        "if NAMESPACE:\n",
        "    backend_config = KubernetesBackendConfig(namespace=NAMESPACE)\n",
        "    client = TrainerClient(backend_config=backend_config)\n",
        "else:\n",
        "    client = TrainerClient()\n",
        "\n",
        "runtime = client.get_runtime(name=\"torch-distributed\")\n",
        "JOB_NAME = client.train(trainer=trainer, runtime=runtime)\n",
        "print(f\"Job submitted: {JOB_NAME}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Monitor progress\n",
        "\n",
        "Progress is available through:\n",
        "1. **OpenShift AI Dashboard** - Visual interface with real-time updates\n",
        "2. **CLI** - TrainJob annotations contain structured progress data\n",
        "\n",
        "Run the cell below to poll progress until the job completes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import subprocess\n",
        "import json\n",
        "import time\n",
        "\n",
        "def get_progress(job_name, namespace=None):\n",
        "    \"\"\"Fetch progress from TrainJob annotations.\"\"\"\n",
        "    ns_arg = f\"-n {namespace}\" if namespace else \"\"\n",
        "    cmd = f\"oc get trainjob {job_name} {ns_arg} -o json\"\n",
        "    result = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
        "    if result.returncode != 0:\n",
        "        return None, None\n",
        "    \n",
        "    data = json.loads(result.stdout)\n",
        "    state = data.get(\"status\", {}).get(\"conditions\", [{}])\n",
        "    state_str = \"Unknown\"\n",
        "    for c in state:\n",
        "        if c.get(\"type\") == \"Complete\" and c.get(\"status\") == \"True\":\n",
        "            state_str = \"Complete\"\n",
        "            break\n",
        "        elif c.get(\"type\") == \"Suspended\" and c.get(\"status\") == \"False\":\n",
        "            state_str = \"Running\"\n",
        "    \n",
        "    annotations = data.get(\"metadata\", {}).get(\"annotations\", {})\n",
        "    progress_str = annotations.get(\"trainer.opendatahub.io/trainerStatus\", \"{}\")\n",
        "    try:\n",
        "        progress = json.loads(progress_str)\n",
        "    except:\n",
        "        progress = {}\n",
        "    \n",
        "    return state_str, progress\n",
        "\n",
        "print(f\"Monitoring job: {JOB_NAME}\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "while True:\n",
        "    state, progress = get_progress(JOB_NAME, NAMESPACE)\n",
        "    \n",
        "    if progress:\n",
        "        pct = progress.get(\"progressPercentage\", 0)\n",
        "        step = progress.get(\"currentStep\", 0)\n",
        "        total = progress.get(\"totalSteps\", 0)\n",
        "        epoch = progress.get(\"currentEpoch\", 0)\n",
        "        epochs = progress.get(\"totalEpochs\", 0)\n",
        "        eta = progress.get(\"estimatedRemainingTimeSummary\", \"calculating...\")\n",
        "        metrics = progress.get(\"trainMetrics\", {})\n",
        "        loss = metrics.get(\"loss\", \"N/A\")\n",
        "        throughput = metrics.get(\"throughput_samples_sec\", \"N/A\")\n",
        "        \n",
        "        print(f\"Progress: {pct}% | Step: {step}/{total} | Epoch: {epoch}/{epochs}\")\n",
        "        print(f\"  Loss: {loss} | Throughput: {throughput} samples/sec | ETA: {eta}\")\n",
        "    else:\n",
        "        print(f\"State: {state} (waiting for progress data...)\")\n",
        "    \n",
        "    if state == \"Complete\":\n",
        "        print(\"-\" * 60)\n",
        "        print(\"Training completed!\")\n",
        "        break\n",
        "    \n",
        "    time.sleep(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. View final progress data\n",
        "\n",
        "The progress annotations remain on the TrainJob after completion, providing a record of the training run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display final progress data\n",
        "_, final_progress = get_progress(JOB_NAME, NAMESPACE)\n",
        "\n",
        "print(\"Final Training Progress:\")\n",
        "print(json.dumps(final_progress, indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Cleanup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Delete the training job\n",
        "client.delete_job(name=JOB_NAME)\n",
        "print(f\"Job {JOB_NAME} deleted\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "In this notebook, you learned:\n",
        "\n",
        "1. **Progress tracking is automatic** - When using `TransformersTrainer`, progress tracking is enabled by default\n",
        "2. **Metrics are stored in annotations** - TrainJob annotations contain structured progress data\n",
        "3. **Real-time visibility** - Monitor steps, epochs, loss, throughput, and ETA as training progresses\n",
        "4. **No code changes required** - Your training function works as-is\n",
        "\n",
        "**Available metrics:**\n",
        "- `progressPercentage` - Overall completion percentage\n",
        "- `currentStep` / `totalSteps` - Training step progress\n",
        "- `currentEpoch` / `totalEpochs` - Epoch progress\n",
        "- `estimatedRemainingSeconds` - Time to completion\n",
        "- `trainMetrics.loss` - Current training loss\n",
        "- `trainMetrics.throughput_samples_sec` - Training throughput\n",
        "\n",
        "**Next steps:**\n",
        "- View progress in the OpenShift AI Dashboard\n",
        "- Try disabling progress tracking with `enable_progression_tracking=False`\n",
        "- Explore JIT checkpointing for fault tolerance"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
